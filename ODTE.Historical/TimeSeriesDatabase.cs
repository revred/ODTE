
using System.Data;
using Microsoft.Data.Sqlite;

namespace ODTE.Historical;

/// <summary>
/// High-performance time series database for ODTE historical data
/// Single SQLite file with optimized schema, compression, and fast range queries
/// </summary>
public class TimeSeriesDatabase : IDisposable
{
    private readonly SqliteConnection _connection;
    private readonly string _dbPath;
    
    public TimeSeriesDatabase(string dbPath = @"C:\code\ODTE\Data\ODTE_TimeSeries_5Y.db")
    {
        _dbPath = dbPath;
        var connectionString = $"Data Source={dbPath};Cache=Shared;";
        _connection = new SqliteConnection(connectionString);
        _connection.Open();
        
        // Enable performance optimizations
        ExecuteNonQuery("PRAGMA journal_mode=WAL");          // Write-Ahead Logging
        ExecuteNonQuery("PRAGMA synchronous=NORMAL");        // Faster writes
        ExecuteNonQuery("PRAGMA cache_size=10000");          // 10MB cache
        ExecuteNonQuery("PRAGMA temp_store=MEMORY");         // Memory temp storage
        ExecuteNonQuery("PRAGMA mmap_size=268435456");       // 256MB memory map
    }

    /// <summary>
    /// Initialize database schema optimized for time series data
    /// </summary>
    public async Task InitializeAsync()
    {
        // Main time series table with optimized storage
        await ExecuteNonQueryAsync(@"
            CREATE TABLE IF NOT EXISTS market_data (
                id INTEGER PRIMARY KEY,
                timestamp INTEGER NOT NULL,                    -- Unix timestamp (8 bytes)
                symbol_id INTEGER NOT NULL,                    -- Symbol lookup (4 bytes)
                open_price INTEGER NOT NULL,                   -- Price * 10000 (4 bytes)
                high_price INTEGER NOT NULL,                   -- Price * 10000 (4 bytes)  
                low_price INTEGER NOT NULL,                    -- Price * 10000 (4 bytes)
                close_price INTEGER NOT NULL,                  -- Price * 10000 (4 bytes)
                volume INTEGER NOT NULL,                       -- Volume (8 bytes)
                vwap_price INTEGER NOT NULL                    -- VWAP * 10000 (4 bytes)
            )");

        // Clustered index on timestamp for fast range queries
        await ExecuteNonQueryAsync(@"
            CREATE UNIQUE INDEX IF NOT EXISTS idx_market_data_time_symbol 
            ON market_data(timestamp, symbol_id)");

        // Symbol lookup table (normalize strings)
        await ExecuteNonQueryAsync(@"
            CREATE TABLE IF NOT EXISTS symbols (
                id INTEGER PRIMARY KEY,
                symbol TEXT UNIQUE NOT NULL,
                description TEXT
            )");

        // Metadata table for data quality and statistics
        await ExecuteNonQueryAsync(@"
            CREATE TABLE IF NOT EXISTS metadata (
                key TEXT PRIMARY KEY,
                value TEXT NOT NULL,
                updated_at INTEGER NOT NULL
            )");

        // Trading calendar for business day lookups
        await ExecuteNonQueryAsync(@"
            CREATE TABLE IF NOT EXISTS trading_calendar (
                date INTEGER PRIMARY KEY,                      -- Date as YYYYMMDD
                is_trading_day INTEGER NOT NULL,               -- 1 or 0
                session_start INTEGER,                         -- Unix timestamp
                session_end INTEGER,                           -- Unix timestamp
                notes TEXT
            )");

        Console.WriteLine($"âœ… Time series database initialized: {_dbPath}");
    }

    /// <summary>
    /// Import data from consolidated Parquet files with compression
    /// </summary>
    public async Task<ImportResult> ImportFromParquetAsync(
        string sourceDirectory = @"C:\code\ODTE\Data\Historical\XSP",
        IProgress<ImportProgress>? progress = null)
    {
        var result = new ImportResult { StartTime = DateTime.UtcNow };
        var symbolId = await GetOrCreateSymbolAsync("XSP", "SPDR S&P 500 Mini ETF");
        
        var files = Directory.GetFiles(sourceDirectory, "*.parquet", SearchOption.AllDirectories)
            .OrderBy(f => f).ToList();
        
        result.TotalFiles = files.Count;
        
        var transaction = _connection.BeginTransaction();
        
        try
        {
            var insertCmd = _connection.CreateCommand();
            insertCmd.CommandText = @"
                INSERT OR REPLACE INTO market_data 
                (timestamp, symbol_id, open_price, high_price, low_price, close_price, volume, vwap_price)
                VALUES (@timestamp, @symbol_id, @open, @high, @low, @close, @volume, @vwap)";
            
            // Prepare parameters for bulk insert
            insertCmd.Parameters.Add("@timestamp", SqliteType.Integer);
            insertCmd.Parameters.Add("@symbol_id", SqliteType.Integer);
            insertCmd.Parameters.Add("@open", SqliteType.Integer);
            insertCmd.Parameters.Add("@high", SqliteType.Integer);
            insertCmd.Parameters.Add("@low", SqliteType.Integer);
            insertCmd.Parameters.Add("@close", SqliteType.Integer);
            insertCmd.Parameters.Add("@volume", SqliteType.Integer);
            insertCmd.Parameters.Add("@vwap", SqliteType.Integer);
            
            int batchSize = 0;
            const int COMMIT_BATCH_SIZE = 10000;
            
            foreach (var file in files)
            {
                try
                {
                    // For this prototype, we'll simulate reading Parquet data
                    // In production, this would use actual Parquet.Net reading
                    var date = ExtractDateFromPath(file);
                    var dayData = GenerateSampleDayData(date, symbolId);
                    
                    foreach (var bar in dayData)
                    {
                        insertCmd.Parameters["@timestamp"].Value = ((DateTimeOffset)bar.Timestamp).ToUnixTimeSeconds();
                        insertCmd.Parameters["@symbol_id"].Value = symbolId;
                        insertCmd.Parameters["@open"].Value = (int)(bar.Open * 10000);
                        insertCmd.Parameters["@high"].Value = (int)(bar.High * 10000);
                        insertCmd.Parameters["@low"].Value = (int)(bar.Low * 10000);
                        insertCmd.Parameters["@close"].Value = (int)(bar.Close * 10000);
                        insertCmd.Parameters["@volume"].Value = bar.Volume;
                        insertCmd.Parameters["@vwap"].Value = (int)(bar.VWAP * 10000);
                        
                        await insertCmd.ExecuteNonQueryAsync();
                        result.RecordsImported++;
                        batchSize++;
                        
                        // Commit in batches for performance
                        if (batchSize >= COMMIT_BATCH_SIZE)
                        {
                            transaction.Commit();
                            transaction.Dispose();
                            transaction = _connection.BeginTransaction();
                            batchSize = 0;
                        }
                    }
                    
                    result.FilesProcessed++;
                    progress?.Report(new ImportProgress
                    {
                        FilesProcessed = result.FilesProcessed,
                        TotalFiles = result.TotalFiles,
                        RecordsImported = result.RecordsImported,
                        CurrentFile = Path.GetFileName(file)
                    });
                }
                catch (Exception ex)
                {
                    result.Errors.Add($"{file}: {ex.Message}");
                }
            }
            
            transaction.Commit();
            transaction.Dispose();
            
            // Update metadata
            await UpdateMetadataAsync("last_import", DateTime.UtcNow.ToString("yyyy-MM-dd HH:mm:ss UTC"));
            await UpdateMetadataAsync("total_records", result.RecordsImported.ToString());
            await UpdateMetadataAsync("date_range_start", result.StartDate?.ToString("yyyy-MM-dd") ?? "");
            await UpdateMetadataAsync("date_range_end", result.EndDate?.ToString("yyyy-MM-dd") ?? "");
            
            // Optimize database after import
            await ExecuteNonQueryAsync("ANALYZE");
            await ExecuteNonQueryAsync("VACUUM");
            
            result.Success = true;
        }
        catch (Exception ex)
        {
            transaction.Rollback();
            transaction.Dispose();
            result.Success = false;
            result.ErrorMessage = ex.Message;
        }
        
        result.EndTime = DateTime.UtcNow;
        result.Duration = result.EndTime - result.StartTime;
        
        return result;
    }

    /// <summary>
    /// Fast range query with optional sampling
    /// </summary>
    public async Task<List<MarketDataBar>> GetRangeAsync(
        DateTime startTime, 
        DateTime endTime, 
        string symbol = "XSP",
        TimeSpan? sampleInterval = null)
    {
        var symbolId = await GetSymbolIdAsync(symbol);
        if (symbolId == null) return new List<MarketDataBar>();
        
        var startUnix = ((DateTimeOffset)startTime).ToUnixTimeSeconds();
        var endUnix = ((DateTimeOffset)endTime).ToUnixTimeSeconds();
        
        string sql;
        if (sampleInterval.HasValue)
        {
            // Downsample data for large ranges
            var intervalSeconds = (int)sampleInterval.Value.TotalSeconds;
            sql = $@"
                SELECT 
                    (timestamp / {intervalSeconds}) * {intervalSeconds} as period_start,
                    AVG(open_price) as avg_open,
                    MAX(high_price) as max_high,
                    MIN(low_price) as min_low,
                    AVG(close_price) as avg_close,
                    SUM(volume) as total_volume,
                    AVG(vwap_price) as avg_vwap
                FROM market_data 
                WHERE timestamp BETWEEN @start AND @end 
                  AND symbol_id = @symbol_id
                GROUP BY timestamp / {intervalSeconds}
                ORDER BY period_start";
        }
        else
        {
            sql = @"
                SELECT timestamp, open_price, high_price, low_price, close_price, volume, vwap_price
                FROM market_data 
                WHERE timestamp BETWEEN @start AND @end 
                  AND symbol_id = @symbol_id
                ORDER BY timestamp";
        }
        
        using var cmd = _connection.CreateCommand();
        cmd.CommandText = sql;
        cmd.Parameters.AddWithValue("@start", startUnix);
        cmd.Parameters.AddWithValue("@end", endUnix);
        cmd.Parameters.AddWithValue("@symbol_id", symbolId);
        
        var results = new List<MarketDataBar>();
        using var reader = await cmd.ExecuteReaderAsync();
        
        while (await reader.ReadAsync())
        {
            results.Add(new MarketDataBar
            {
                Timestamp = DateTimeOffset.FromUnixTimeSeconds(reader.GetInt64(0)).DateTime,
                Open = reader.GetInt32(1) / 10000.0,
                High = reader.GetInt32(2) / 10000.0,
                Low = reader.GetInt32(3) / 10000.0,
                Close = reader.GetInt32(4) / 10000.0,
                Volume = reader.GetInt64(5),
                VWAP = reader.GetInt32(6) / 10000.0
            });
        }
        
        return results;
    }

    /// <summary>
    /// Export range to various formats
    /// </summary>
    public async Task<ExportResult> ExportRangeAsync(
        DateTime startTime, 
        DateTime endTime,
        string outputPath,
        ExportFormat format,
        string symbol = "XSP",
        TimeSpan? sampleInterval = null)
    {
        var data = await GetRangeAsync(startTime, endTime, symbol, sampleInterval);
        var result = new ExportResult 
        { 
            OutputPath = outputPath,
            RecordsExported = data.Count
        };
        
        var exportStartTime = DateTime.UtcNow;
        
        try
        {
            switch (format)
            {
                case ExportFormat.CSV:
                    await ExportToCsvAsync(data, outputPath);
                    break;
                case ExportFormat.JSON:
                    await ExportToJsonAsync(data, outputPath);
                    break;
                case ExportFormat.Parquet:
                    await ExportToParquetAsync(data, outputPath);
                    break;
                default:
                    throw new ArgumentException($"Unsupported export format: {format}");
            }
            
            result.Success = true;
            result.FileSizeBytes = new FileInfo(outputPath).Length;
        }
        catch (Exception ex)
        {
            result.Success = false;
            result.ErrorMessage = ex.Message;
        }
        
        result.ExportDuration = DateTime.UtcNow - exportStartTime;
        
        return result;
    }

    /// <summary>
    /// Get database statistics and health metrics
    /// </summary>
    public async Task<DatabaseStats> GetStatsAsync()
    {
        var stats = new DatabaseStats();
        
        // Record counts
        using var countCmd = _connection.CreateCommand();
        countCmd.CommandText = "SELECT COUNT(*) FROM market_data";
        stats.TotalRecords = Convert.ToInt64(await countCmd.ExecuteScalarAsync());
        
        // Date range
        using var rangeCmd = _connection.CreateCommand();
        rangeCmd.CommandText = @"
            SELECT MIN(timestamp), MAX(timestamp) 
            FROM market_data";
        using var rangeReader = await rangeCmd.ExecuteReaderAsync();
        if (await rangeReader.ReadAsync() && !rangeReader.IsDBNull(0) && !rangeReader.IsDBNull(1))
        {
            stats.StartDate = DateTimeOffset.FromUnixTimeSeconds(rangeReader.GetInt64(0)).DateTime;
            stats.EndDate = DateTimeOffset.FromUnixTimeSeconds(rangeReader.GetInt64(1)).DateTime;
        }
        else
        {
            // Empty database
            stats.StartDate = DateTime.MinValue;
            stats.EndDate = DateTime.MinValue;
        }
        
        // Database size
        var fileInfo = new FileInfo(_dbPath);
        stats.DatabaseSizeBytes = fileInfo.Exists ? fileInfo.Length : 0;
        stats.DatabaseSizeMB = stats.DatabaseSizeBytes / (1024.0 * 1024.0);
        
        // Compression ratio estimate
        var uncompressedSize = stats.TotalRecords * 64; // ~64 bytes per record uncompressed
        stats.CompressionRatio = uncompressedSize > 0 ? (double)uncompressedSize / stats.DatabaseSizeBytes : 0;
        
        return stats;
    }

    // Helper methods
    private async Task<int> GetOrCreateSymbolAsync(string symbol, string description = "")
    {
        var id = await GetSymbolIdAsync(symbol);
        if (id.HasValue) return id.Value;
        
        using var cmd = _connection.CreateCommand();
        cmd.CommandText = "INSERT INTO symbols (symbol, description) VALUES (@symbol, @desc); SELECT last_insert_rowid()";
        cmd.Parameters.AddWithValue("@symbol", symbol);
        cmd.Parameters.AddWithValue("@desc", description);
        
        var result = await cmd.ExecuteScalarAsync();
        return Convert.ToInt32(result);
    }
    
    private async Task<int?> GetSymbolIdAsync(string symbol)
    {
        using var cmd = _connection.CreateCommand();
        cmd.CommandText = "SELECT id FROM symbols WHERE symbol = @symbol";
        cmd.Parameters.AddWithValue("@symbol", symbol);
        
        var result = await cmd.ExecuteScalarAsync();
        return result != null ? Convert.ToInt32(result) : null;
    }
    
    private async Task UpdateMetadataAsync(string key, string value)
    {
        using var cmd = _connection.CreateCommand();
        cmd.CommandText = @"
            INSERT OR REPLACE INTO metadata (key, value, updated_at) 
            VALUES (@key, @value, @timestamp)";
        cmd.Parameters.AddWithValue("@key", key);
        cmd.Parameters.AddWithValue("@value", value);
        cmd.Parameters.AddWithValue("@timestamp", DateTimeOffset.UtcNow.ToUnixTimeSeconds());
        
        await cmd.ExecuteNonQueryAsync();
    }
    
    private DateTime ExtractDateFromPath(string filePath)
    {
        var fileName = Path.GetFileNameWithoutExtension(filePath);
        if (DateTime.TryParseExact(fileName, "yyyyMMdd", null, System.Globalization.DateTimeStyles.None, out var date))
            return date;
        return DateTime.MinValue;
    }
    
    private List<MarketDataBar> GenerateSampleDayData(DateTime date, int symbolId)
    {
        // Generate ~390 minute bars for a trading day (9:30 AM - 4:00 PM EST)
        var data = new List<MarketDataBar>();
        var startTime = date.Date.AddHours(9).AddMinutes(30); // 9:30 AM
        var basePrice = 450.0; // Approximate XSP price
        
        for (int i = 0; i < 390; i++) // 390 minutes in trading day
        {
            var timestamp = startTime.AddMinutes(i);
            var randomChange = (new Random().NextDouble() - 0.5) * 2.0; // Â±$1 random walk
            
            data.Add(new MarketDataBar
            {
                Timestamp = timestamp,
                Open = basePrice + randomChange,
                High = basePrice + randomChange + 0.25,
                Low = basePrice + randomChange - 0.25, 
                Close = basePrice + randomChange + 0.1,
                Volume = new Random().NextInt64(1000, 10000),
                VWAP = basePrice + randomChange + 0.05
            });
        }
        
        return data;
    }
    
    private async Task ExportToCsvAsync(List<MarketDataBar> data, string outputPath)
    {
        using var writer = new StreamWriter(outputPath);
        await writer.WriteLineAsync("Timestamp,Open,High,Low,Close,Volume,VWAP");
        
        foreach (var bar in data)
        {
            await writer.WriteLineAsync($"{bar.Timestamp:yyyy-MM-dd HH:mm:ss}," +
                                      $"{bar.Open:F4},{bar.High:F4},{bar.Low:F4}," +
                                      $"{bar.Close:F4},{bar.Volume},{bar.VWAP:F4}");
        }
    }
    
    private async Task ExportToJsonAsync(List<MarketDataBar> data, string outputPath)
    {
        var json = System.Text.Json.JsonSerializer.Serialize(data, new System.Text.Json.JsonSerializerOptions 
        { 
            WriteIndented = true 
        });
        await File.WriteAllTextAsync(outputPath, json);
    }
    
    private async Task ExportToParquetAsync(List<MarketDataBar> data, string outputPath)
    {
        await Task.Delay(0); // Simulate async delay for testing purposes
        // This would require Parquet.Net library
        // For now, throw not implemented
        throw new NotImplementedException("Parquet export requires Parquet.Net library");
    }
    
    private void ExecuteNonQuery(string sql)
    {
        using var cmd = _connection.CreateCommand();
        cmd.CommandText = sql;
        cmd.ExecuteNonQuery();
    }
    
    private async Task ExecuteNonQueryAsync(string sql)
    {
        using var cmd = _connection.CreateCommand();
        cmd.CommandText = sql;
        await cmd.ExecuteNonQueryAsync();
    }

    public void Dispose()
    {
        _connection?.Dispose();
    }
}

// Data structures
public class MarketDataBar
{
    public DateTime Timestamp { get; set; }
    public double Open { get; set; }
    public double High { get; set; }
    public double Low { get; set; }
    public double Close { get; set; }
    public long Volume { get; set; }
    public double VWAP { get; set; }
}

public class ImportResult
{
    public bool Success { get; set; }
    public DateTime StartTime { get; set; }
    public DateTime EndTime { get; set; }
    public TimeSpan Duration { get; set; }
    public string? ErrorMessage { get; set; }
    
    public int TotalFiles { get; set; }
    public int FilesProcessed { get; set; }
    public long RecordsImported { get; set; }
    public DateTime? StartDate { get; set; }
    public DateTime? EndDate { get; set; }
    public List<string> Errors { get; set; } = new();
}

public class ImportProgress
{
    public int FilesProcessed { get; set; }
    public int TotalFiles { get; set; }
    public long RecordsImported { get; set; }
    public string CurrentFile { get; set; } = string.Empty;
    public double ProgressPercentage => TotalFiles > 0 ? (double)FilesProcessed / TotalFiles * 100 : 0;
}


public class DatabaseStats
{
    public long TotalRecords { get; set; }
    public DateTime StartDate { get; set; }
    public DateTime EndDate { get; set; }
    public long DatabaseSizeBytes { get; set; }
    public double DatabaseSizeMB { get; set; }
    public double CompressionRatio { get; set; }
    public TimeSpan DateRange => EndDate - StartDate;
    public int TradingDays => (int)(DateRange.TotalDays * 5.0 / 7.0); // Rough estimate
}

public enum ExportFormat
{
    CSV,
    JSON,
    Parquet
}